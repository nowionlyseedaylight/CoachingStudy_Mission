{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5week.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSIWN894S/0897jPjAUESc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. DataLoader를 이용해 MNIST 데이터셋 로드"
      ],
      "metadata": {
        "id": "ZTNhg0AKJgIr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wECglBQ5G_Yt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "training_epochs = 15  # training 반복 횟수\n",
        "batch_size = 100\n",
        "\n",
        "root = './data'\n",
        "mnist_train = dset.MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
        "mnist_test = dset.MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "# data loader를 구현\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 데이터가 준비되었다면, 이젠 그 데이터를 학습할 모델을 구현할 차례입니다. 그 후 모델 안의 가중치를 초기화시켜보세요. 입력 데이터 형태에 맞도록 linear한 모델을 구성해보세요."
      ],
      "metadata": {
        "id": "OzOJlHW_Jk5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "linear = torch.nn.Linear(784, 10, bias=True).to(device)\n",
        "torch.nn.init.normal_(linear.weight)  # weight 초기화"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rlbOnoFJL2v",
        "outputId": "ad239418-7ab8-4b2d-e93b-878f120ea124"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-2.5395,  1.1449, -0.7209,  ..., -0.8589, -2.8663, -1.2511],\n",
              "        [ 0.9226,  0.6787,  1.3152,  ..., -0.2271,  1.0642, -0.0929],\n",
              "        [ 1.1027, -0.1464, -2.0619,  ...,  0.2932, -0.2545,  1.6537],\n",
              "        ...,\n",
              "        [-0.4417, -0.1979,  0.4105,  ...,  0.1739, -0.8267,  0.5866],\n",
              "        [-1.7455, -0.1817, -0.7749,  ...,  0.2513,  0.4484, -0.7206],\n",
              "        [ 0.0127,  0.8570,  0.3458,  ..., -1.8873, -3.0059, -0.9351]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 아래 제시된 loss 함수와 optimizer를 구현해보세요."
      ],
      "metadata": {
        "id": "RRWjRNuDKAaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss fn - Cross Entropy Loss\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# optimizer - SGD\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "pXdGwxwUKJ6R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. 모델, optimizer, loss fn 등을 이용해 학습 구현하기"
      ],
      "metadata": {
        "id": "Ud5wDjmfL1o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs):\n",
        "  for i, (imgs, labels) in enumerate(train_loader): # 리스트 순서, value 전달\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "    imgs = imgs.view(-1, 28*28)\n",
        "\n",
        "    outputs = linear(imgs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, argmax = torch.max(outputs, 1)\n",
        "    accuracy = (labels == argmax).float().mean()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print('Epoch [{}/{}], Steop [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
        "          epoch+1, training_epochs, i+1, len(train_loader), loss.item(), accuracy.item()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVzwr6bFKDTt",
        "outputId": "cc79d8cf-dd1d-4a1f-abd9-ec8218229b21"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Steop [100/600], Loss: 5.1447, Accuracy: 33.00%\n",
            "Epoch [1/15], Steop [200/600], Loss: 2.3513, Accuracy: 51.00%\n",
            "Epoch [1/15], Steop [300/600], Loss: 2.3606, Accuracy: 63.00%\n",
            "Epoch [1/15], Steop [400/600], Loss: 1.4759, Accuracy: 69.00%\n",
            "Epoch [1/15], Steop [500/600], Loss: 1.0778, Accuracy: 77.00%\n",
            "Epoch [1/15], Steop [600/600], Loss: 0.8432, Accuracy: 77.00%\n",
            "Epoch [2/15], Steop [100/600], Loss: 0.6664, Accuracy: 83.00%\n",
            "Epoch [2/15], Steop [200/600], Loss: 1.1041, Accuracy: 74.00%\n",
            "Epoch [2/15], Steop [300/600], Loss: 0.8450, Accuracy: 84.00%\n",
            "Epoch [2/15], Steop [400/600], Loss: 1.5385, Accuracy: 76.00%\n",
            "Epoch [2/15], Steop [500/600], Loss: 1.4800, Accuracy: 73.00%\n",
            "Epoch [2/15], Steop [600/600], Loss: 0.9173, Accuracy: 78.00%\n",
            "Epoch [3/15], Steop [100/600], Loss: 1.0738, Accuracy: 81.00%\n",
            "Epoch [3/15], Steop [200/600], Loss: 1.1980, Accuracy: 77.00%\n",
            "Epoch [3/15], Steop [300/600], Loss: 0.9031, Accuracy: 83.00%\n",
            "Epoch [3/15], Steop [400/600], Loss: 0.5138, Accuracy: 84.00%\n",
            "Epoch [3/15], Steop [500/600], Loss: 0.7423, Accuracy: 77.00%\n",
            "Epoch [3/15], Steop [600/600], Loss: 0.8472, Accuracy: 83.00%\n",
            "Epoch [4/15], Steop [100/600], Loss: 1.0365, Accuracy: 81.00%\n",
            "Epoch [4/15], Steop [200/600], Loss: 0.5098, Accuracy: 90.00%\n",
            "Epoch [4/15], Steop [300/600], Loss: 0.7291, Accuracy: 86.00%\n",
            "Epoch [4/15], Steop [400/600], Loss: 0.9434, Accuracy: 83.00%\n",
            "Epoch [4/15], Steop [500/600], Loss: 0.6671, Accuracy: 82.00%\n",
            "Epoch [4/15], Steop [600/600], Loss: 0.5323, Accuracy: 89.00%\n",
            "Epoch [5/15], Steop [100/600], Loss: 0.7429, Accuracy: 79.00%\n",
            "Epoch [5/15], Steop [200/600], Loss: 1.1068, Accuracy: 82.00%\n",
            "Epoch [5/15], Steop [300/600], Loss: 0.6080, Accuracy: 82.00%\n",
            "Epoch [5/15], Steop [400/600], Loss: 0.9870, Accuracy: 83.00%\n",
            "Epoch [5/15], Steop [500/600], Loss: 0.8493, Accuracy: 81.00%\n",
            "Epoch [5/15], Steop [600/600], Loss: 0.4534, Accuracy: 89.00%\n",
            "Epoch [6/15], Steop [100/600], Loss: 0.3194, Accuracy: 88.00%\n",
            "Epoch [6/15], Steop [200/600], Loss: 0.4256, Accuracy: 90.00%\n",
            "Epoch [6/15], Steop [300/600], Loss: 0.6269, Accuracy: 85.00%\n",
            "Epoch [6/15], Steop [400/600], Loss: 0.7078, Accuracy: 87.00%\n",
            "Epoch [6/15], Steop [500/600], Loss: 1.0538, Accuracy: 79.00%\n",
            "Epoch [6/15], Steop [600/600], Loss: 0.5864, Accuracy: 82.00%\n",
            "Epoch [7/15], Steop [100/600], Loss: 0.7098, Accuracy: 84.00%\n",
            "Epoch [7/15], Steop [200/600], Loss: 0.7602, Accuracy: 87.00%\n",
            "Epoch [7/15], Steop [300/600], Loss: 0.3546, Accuracy: 91.00%\n",
            "Epoch [7/15], Steop [400/600], Loss: 0.5152, Accuracy: 89.00%\n",
            "Epoch [7/15], Steop [500/600], Loss: 0.5678, Accuracy: 89.00%\n",
            "Epoch [7/15], Steop [600/600], Loss: 0.5024, Accuracy: 85.00%\n",
            "Epoch [8/15], Steop [100/600], Loss: 0.5396, Accuracy: 86.00%\n",
            "Epoch [8/15], Steop [200/600], Loss: 0.5034, Accuracy: 84.00%\n",
            "Epoch [8/15], Steop [300/600], Loss: 0.3192, Accuracy: 93.00%\n",
            "Epoch [8/15], Steop [400/600], Loss: 0.4001, Accuracy: 90.00%\n",
            "Epoch [8/15], Steop [500/600], Loss: 0.6129, Accuracy: 83.00%\n",
            "Epoch [8/15], Steop [600/600], Loss: 0.4726, Accuracy: 88.00%\n",
            "Epoch [9/15], Steop [100/600], Loss: 0.3523, Accuracy: 91.00%\n",
            "Epoch [9/15], Steop [200/600], Loss: 0.5277, Accuracy: 87.00%\n",
            "Epoch [9/15], Steop [300/600], Loss: 0.6400, Accuracy: 89.00%\n",
            "Epoch [9/15], Steop [400/600], Loss: 0.1526, Accuracy: 97.00%\n",
            "Epoch [9/15], Steop [500/600], Loss: 0.5994, Accuracy: 89.00%\n",
            "Epoch [9/15], Steop [600/600], Loss: 0.3465, Accuracy: 89.00%\n",
            "Epoch [10/15], Steop [100/600], Loss: 0.4801, Accuracy: 90.00%\n",
            "Epoch [10/15], Steop [200/600], Loss: 0.4417, Accuracy: 86.00%\n",
            "Epoch [10/15], Steop [300/600], Loss: 0.4441, Accuracy: 87.00%\n",
            "Epoch [10/15], Steop [400/600], Loss: 0.4707, Accuracy: 90.00%\n",
            "Epoch [10/15], Steop [500/600], Loss: 0.6953, Accuracy: 84.00%\n",
            "Epoch [10/15], Steop [600/600], Loss: 0.3527, Accuracy: 91.00%\n",
            "Epoch [11/15], Steop [100/600], Loss: 0.2219, Accuracy: 94.00%\n",
            "Epoch [11/15], Steop [200/600], Loss: 0.4304, Accuracy: 93.00%\n",
            "Epoch [11/15], Steop [300/600], Loss: 0.2636, Accuracy: 91.00%\n",
            "Epoch [11/15], Steop [400/600], Loss: 0.3147, Accuracy: 92.00%\n",
            "Epoch [11/15], Steop [500/600], Loss: 0.3309, Accuracy: 90.00%\n",
            "Epoch [11/15], Steop [600/600], Loss: 0.5702, Accuracy: 86.00%\n",
            "Epoch [12/15], Steop [100/600], Loss: 0.4766, Accuracy: 89.00%\n",
            "Epoch [12/15], Steop [200/600], Loss: 0.3328, Accuracy: 90.00%\n",
            "Epoch [12/15], Steop [300/600], Loss: 0.6349, Accuracy: 84.00%\n",
            "Epoch [12/15], Steop [400/600], Loss: 0.6186, Accuracy: 83.00%\n",
            "Epoch [12/15], Steop [500/600], Loss: 0.3577, Accuracy: 92.00%\n",
            "Epoch [12/15], Steop [600/600], Loss: 0.7642, Accuracy: 85.00%\n",
            "Epoch [13/15], Steop [100/600], Loss: 0.6860, Accuracy: 85.00%\n",
            "Epoch [13/15], Steop [200/600], Loss: 0.3030, Accuracy: 92.00%\n",
            "Epoch [13/15], Steop [300/600], Loss: 0.8021, Accuracy: 86.00%\n",
            "Epoch [13/15], Steop [400/600], Loss: 0.5327, Accuracy: 87.00%\n",
            "Epoch [13/15], Steop [500/600], Loss: 0.6211, Accuracy: 84.00%\n",
            "Epoch [13/15], Steop [600/600], Loss: 0.2070, Accuracy: 92.00%\n",
            "Epoch [14/15], Steop [100/600], Loss: 0.3924, Accuracy: 90.00%\n",
            "Epoch [14/15], Steop [200/600], Loss: 0.2982, Accuracy: 94.00%\n",
            "Epoch [14/15], Steop [300/600], Loss: 0.2990, Accuracy: 89.00%\n",
            "Epoch [14/15], Steop [400/600], Loss: 0.5213, Accuracy: 91.00%\n",
            "Epoch [14/15], Steop [500/600], Loss: 0.4907, Accuracy: 86.00%\n",
            "Epoch [14/15], Steop [600/600], Loss: 0.5799, Accuracy: 84.00%\n",
            "Epoch [15/15], Steop [100/600], Loss: 0.3918, Accuracy: 86.00%\n",
            "Epoch [15/15], Steop [200/600], Loss: 0.1377, Accuracy: 96.00%\n",
            "Epoch [15/15], Steop [300/600], Loss: 0.6270, Accuracy: 85.00%\n",
            "Epoch [15/15], Steop [400/600], Loss: 0.4386, Accuracy: 88.00%\n",
            "Epoch [15/15], Steop [500/600], Loss: 0.2838, Accuracy: 94.00%\n",
            "Epoch [15/15], Steop [600/600], Loss: 0.3626, Accuracy: 85.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. 테스트 데이터로 테스트 진행"
      ],
      "metadata": {
        "id": "EOGoAXN6Ng0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear.eval()\n",
        "with torch.no_grad():\n",
        "  correct=0\n",
        "  total=0\n",
        "  for i, (imgs, labels) in enumerate(test_loader):\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "    imgs = imgs.view(-1, 28*28)\n",
        "    outputs = linear(imgs)\n",
        "    _, argmax = torch.max(outputs, 1)  # amx함수 통해 최종 출력이 가장 높은 class 선택\n",
        "    total += imgs.size(0)\n",
        "    correct += (labels == argmax).sum().item()\n",
        "\n",
        "  print('Test accuracy for {} images: {:.2f}%'.format(total, correct / total * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RFWsiOYMwFS",
        "outputId": "e29926bd-6ef3-4c9d-8f99-33bb6ad202a5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for 10000 images: 89.18%\n"
          ]
        }
      ]
    }
  ]
}